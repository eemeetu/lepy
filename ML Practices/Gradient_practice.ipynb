{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgQyWw5o7Nej"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGD1wQgMruJw"
      },
      "source": [
        "Реализация класса ```LinearRegressionSGD``` c обучением и и применением линейной регрессии, построенной с помощью стохастического градиентного спуска."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZxdV27R9-uc"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class LinearRegressionSGD(BaseEstimator):\n",
        "    def __init__(self, epsilon=1e-4, max_steps=100, w0=None, alpha=1e-4):\n",
        "        \"\"\"\n",
        "        epsilon: разница для нормы изменения весов\n",
        "        max_steps: максимальное количество шагов в градиентном спуске\n",
        "        w0: np.array (d,) - начальные веса\n",
        "        alpha: шаг обучения\n",
        "        \"\"\"\n",
        "        self.epsilon = epsilon\n",
        "        self.max_steps = max_steps\n",
        "        self.w0 = w0\n",
        "        self.alpha = alpha\n",
        "        self.w = None\n",
        "        self.w_history = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: self\n",
        "        \"\"\"\n",
        "        l, d = X.shape\n",
        "\n",
        "        if self.w0 is None:\n",
        "          self.w0 = np.zeros(d)\n",
        "\n",
        "        self.w = self.w0\n",
        "\n",
        "        for step in range(self.max_steps):\n",
        "          self.w_history.append(self.w)\n",
        "\n",
        "          w_new = self.w - self.alpha * self.calc_gradient(X, y)\n",
        "\n",
        "          if (np.linalg.norm(w_new - self.w) < self.epsilon):\n",
        "            break\n",
        "\n",
        "          self.w = w_new\n",
        "\n",
        "        return self\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        ---\n",
        "        output: np.array (l)\n",
        "        \"\"\"\n",
        "        if self.w is None:\n",
        "            raise Exception('Not trained yet')\n",
        "\n",
        "        l, d = X.shape\n",
        "\n",
        "        y_pred = []\n",
        "\n",
        "        for i in range(l):\n",
        "          y_pred.append(np.dot(X[i], self.w))\n",
        "\n",
        "        return np.array(y_pred)\n",
        "        return y_pred\n",
        "\n",
        "    def calc_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: np.array (d)\n",
        "        \"\"\"\n",
        "\n",
        "        l, d = X.shape\n",
        "        gradient = []\n",
        "\n",
        "        for j in range(d):\n",
        "          dQ = 0\n",
        "          i = np.random.choice(range(l))\n",
        "          dQ += (2/l) * X[i][j] * (np.dot(X[i], self.w) - y[i])\n",
        "          gradient.append(dQ)\n",
        "\n",
        "        return np.array(gradient)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNOm9-bXpdT3"
      },
      "source": [
        "Проверять работу мы будем на имеющемся в sklearn наборе данных boston: в нём нужно по информации о доме предсказать его стоимость."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.1.3"
      ],
      "metadata": {
        "id": "eGfuxaks0PvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c24JCwes9-pe"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_boston()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(X), y, test_size=0.3, random_state=10)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eIJwWnInXnr"
      },
      "source": [
        "Метрикой качества будет MAPE - Mean Absolute Percentage Error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znoDavxyuLsi"
      },
      "source": [
        "def MAPE(y_true, y_pred):\n",
        "    \"\"\"\n",
        "        y_true: np.array (l)\n",
        "        y_pred: np.array (l)\n",
        "        ---\n",
        "        output: float [0, +inf)\n",
        "    \"\"\"\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true))*100\n",
        "\n",
        "    return mape"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_0 = np.full(y_test.shape, np.mean(y_test))"
      ],
      "metadata": {
        "id": "hP-NlFuM1Y5f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_0"
      ],
      "metadata": {
        "id": "i_dHOTnK1oLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6mTAykeojwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58f86e7-ad68-46ff-805a-fc768721f11c"
      },
      "source": [
        "MAPE(y_test, y_0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37.41588297684096"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nNy2ITxuMKf"
      },
      "source": [
        "Обучение ```LinearRegressionSGD``` с базовыми параметрами на тренировочном наборе данных (```X_train```, ```y_train```)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BIHwAwUvB-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c740a73-656b-4930-a6b8-1b6e7018c923"
      },
      "source": [
        "sgd = LinearRegressionSGD()\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "y_pred_sgd = sgd.predict(X_test)\n",
        "\n",
        "MAPE(y_test, y_pred_sgd)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39.31827706027169"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWappMdMtIPV"
      },
      "source": [
        "Вычисление весов по точной формуле, используя ```X_train``` и ```y_train```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjMUlPje9-k0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08347305-42d7-41b8-f6d9-d4a77c0e327b"
      },
      "source": [
        "w_true = np.linalg.inv(X_train.T @ X_train) @ X_train.T @ y_train\n",
        "y_pred_lr = np.dot(X_test, w_true)\n",
        "\n",
        "MAPE(y_test, y_pred_lr)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.95313481637632"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZFaUn7yx04u"
      },
      "source": [
        "Чтобы избежать переобучения, предлагается добавить к оптимизируемому функционалу L2-норму весов; таким образом, будем решать задачу гребневой регрессии, Ridge:\n",
        "\n",
        "$$ \\frac{1}{l}(Xw-y)^T(Xw-y) +\\gamma||w||_2 \\rightarrow \\min_{w}. $$\n",
        "\n",
        "Обучение такой модели в матричном виде."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEXqBqmGxWDz"
      },
      "source": [
        "class RidgeSGD(BaseEstimator):\n",
        "    def __init__(self, epsilon=1e-4, max_steps=1000, w0=None, alpha=1e-2, gamma=0):\n",
        "        \"\"\"\n",
        "        epsilon: разница для нормы изменения весов\n",
        "        max_steps: максимальное количество шагов в градиентном спуске\n",
        "        w0: np.array (d,) - начальные веса\n",
        "        alpha: шаг обучения\n",
        "        gamma: коэффициент регуляризации\n",
        "        \"\"\"\n",
        "        self.epsilon = epsilon\n",
        "        self.max_steps = max_steps\n",
        "        self.w0 = w0\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.w = None\n",
        "        self.w_history = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: self\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        ---\n",
        "        output: np.array (l)\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def calc_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: np.array (d)\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t9rqXFu8Pq6"
      },
      "source": [
        "Y_pred_ridge, значение MAPE(y_test, y_pred_ridge)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A2hak_A8QPO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}